Last week, I worked on finding the best method to clean up my data and fix grammatical errors in my training dataset before feeding it into my model. I discovered that using the ChatGPT API was sometimes producing strange, unreadable lines in the output and was not correcting all grammatical errors in my dataset. I think one issue is that I’ve been attempting to fix errors line by line, whereas my data is structured so that each pair of lines represents a customer–agent interaction. It might be more effective to process each pair together instead of individually.

I also experimented with the language_tool_python library, but found its runtime to be significantly longer compared to the ChatGPT API. Because of this, I’m leaning toward continuing with the ChatGPT API despite its quirks.

This week, I plan to continue refining my data cleaning process. I’ve been spending a lot of time debugging lately, and if I can’t get my current dataset cleaned to my satisfaction, I’ll likely search Kaggle for better-prepared data—there’s plenty available. My mindset has shifted somewhat: originally, I wanted to deeply understand all of the underlying code, but I’ve realized that this approach has taken time away from actually getting a working solution. I still think it’s important to have a baseline understanding, but for now, it makes more sense to learn how to use and adapt the tools available to me. I can dive deeper into the inner workings later, perhaps in a dedicated course.

Some of my current challenges include the long runtimes of API calls, which make debugging slow—if there’s a bug, it takes a while to detect and fix. Another challenge is figuring out the most effective way to clean the data. If I need to switch methods, that will require additional research and implementation time.

Overall, I think my process last week was fairly efficient. I felt genuinely excited about the project, which helped me stay focused and motivated. Knowing that I might have something viable by the end of the course has given me more drive than I’ve had in previous weeks.